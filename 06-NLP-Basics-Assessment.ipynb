{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basics Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 ère partie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL to perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Créer un objet Doc à partir du fichier `owlcreek.txt`**<br>\n",
    "> HINT: Use `with open('../TextFiles/owlcreek.txt') as f:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AN OCCURRENCE AT OWL CREEK BRIDGE\n",
       "\n",
       "by Ambrose Bierce\n",
       "\n",
       "I\n",
       "\n",
       "A man stood upon a railroad bridge in northern Alabama, looking down\n",
       "into the swift water twenty feet below.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to verify it worked:\n",
    "\n",
    "doc[:36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Combien de tokens sont contenus dans le fichier ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4833"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Combien de phrases sont contenues dans le fichier ?<br>HINT: Vous devez d'abord créer une liste !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Imprimer la deuxième phrase du document**<br> HINT: L'indexation commence à zéro et le titre compte comme la première phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A man stood upon a railroad bridge in northern Alabama, looking down\n",
      "into the swift water twenty feet below.  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Pour chaque élément de la phrase ci-dessus, imprimez son`text`, `POS` tag, `dep` tag and `lemma`<br>\n",
    "CHALLENGE: Faire en sorte que les valeurs s'alignent en colonnes dans la sortie imprimée.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A DET det a\n",
      "man NOUN nsubj man\n",
      "stood VERB ROOT stand\n",
      "upon ADP prep upon\n",
      "a DET det a\n",
      "railroad NOUN compound railroad\n",
      "bridge NOUN pobj bridge\n",
      "in ADP prep in\n",
      "northern ADJ amod northern\n",
      "Alabama PROPN pobj alabama\n",
      ", PUNCT punct ,\n",
      "looking VERB advcl look\n",
      "down PART prt down\n",
      "\n",
      " SPACE  \n",
      "\n",
      "into ADP prep into\n",
      "the DET det the\n",
      "swift ADJ amod swift\n",
      "water NOUN pobj water\n",
      "twenty NUM nummod twenty\n",
      "feet NOUN npadvmod foot\n",
      "below ADV advmod below\n",
      ". PUNCT punct .\n",
      "  SPACE   \n"
     ]
    }
   ],
   "source": [
    "# NORMAL SOLUTION:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A               DET   det        a              \n",
      "man             NOUN  nsubj      man            \n",
      "stood           VERB  ROOT       stand          \n",
      "upon            ADP   prep       upon           \n",
      "a               DET   det        a              \n",
      "railroad        NOUN  compound   railroad       \n",
      "bridge          NOUN  pobj       bridge         \n",
      "in              ADP   prep       in             \n",
      "northern        ADJ   amod       northern       \n",
      "Alabama         PROPN pobj       alabama        \n",
      ",               PUNCT punct      ,              \n",
      "looking         VERB  advcl      look           \n",
      "down            PART  prt        down           \n",
      "\n",
      "               SPACE            \n",
      "              \n",
      "into            ADP   prep       into           \n",
      "the             DET   det        the            \n",
      "swift           ADJ   amod       swift          \n",
      "water           NOUN  pobj       water          \n",
      "twenty          NUM   nummod     twenty         \n",
      "feet            NOUN  npadvmod   foot           \n",
      "below           ADV   advmod     below          \n",
      ".               PUNCT punct      .              \n",
      "                SPACE                           \n"
     ]
    }
   ],
   "source": [
    "# CHALLENGE SOLUTION:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 ème partie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 1: Tokenisation de phrases avec SpaCy\n",
    "\n",
    "Question : Créez une phrase complexe en anglais et utilisez SpaCy pour la tokeniser en phrases individuelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenization is a fundamental step in NLP.', 'It involves breaking down a text into smaller units called tokens.']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 2\n",
    "\n",
    "Question : Utilisez SpaCy pour tokeniser la phrase complexe en mots.\n",
    "\n",
    "Question : Quels avantages offre SpaCy par rapport à d'autres bibliothèques pour la tokenisation?\n",
    "\n",
    "Question : Créez une fonction custom_spacy_tokenizer qui prend une phrase en entrée, utilise SpaCy pour la tokeniser et renvoie les tokens en minuscules.\n",
    "\n",
    "Question : Appliquez votre fonction custom_spacy_tokenizer à une phrase de votre choix et affichez les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenization', 'is', 'a', 'fundamental', 'step', 'in', 'NLP', '.', 'It', 'involves', 'breaking', 'down', 'a', 'text', 'into', 'smaller', 'units', 'called', 'tokens', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenisation en mots avec SpaCy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tokenization', 'is', 'a', 'fundamental', 'step', 'in', 'nlp', '.', 'it', 'involves', 'breaking', 'down', 'a', 'text', 'into', 'smaller', 'units', 'called', 'tokens', '.']\n"
     ]
    }
   ],
   "source": [
    "# Fonction de tokenisation personnalisée avec SpaCy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 3\n",
    "\n",
    "Question : Utilisez SpaCy pour extraire les lemmes et les POS de la phrase complexe.\n",
    "\n",
    "Question : Comment SpaCy gère-t-il la tokenisation des entités nommées? Testez cela sur une phrase contenant une entité nommée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entity: Apple, Label: ORG\n"
     ]
    }
   ],
   "source": [
    "# Tokenisation des entités nommées avec SpaCy\n",
    "text_with_entity = \"Apple is a major technology company.\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execice 1\n",
    "\n",
    "Question : Créez une phrase complexe en anglais.\n",
    "\n",
    "Question : Utilisez SpaCy pour effectuer le stemming sur les mots de la phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['Stemming', 'is', 'an', 'essential', 'part', 'of', 'natural', 'language', 'processing', '.', 'It', 'involves', 'reducing', 'words', 'to', 'their', 'base', 'form', '.']\n",
      "\n",
      "\n",
      "Stems: ['stem', 'be', 'an', 'essential', 'part', 'of', 'natural', 'language', 'processing', '.', '-pron-', 'involve', 'reduce', 'word', 'to', '-pron-', 'base', 'form', '.']\n"
     ]
    }
   ],
   "source": [
    "# Création d'une phrase complexe\n",
    "text = \"Stemming is an essential part of natural language processing. It involves reducing words to their base form.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 2\n",
    "\n",
    "Question : Créez une fonction custom_spacy_stemmer qui prend une phrase en entrée, utilise SpaCy pour effectuer le stemming, et renvoie les stems en minuscules.\n",
    "\n",
    "Question : Appliquez votre fonction custom_spacy_stemmer à une phrase de votre choix et affichez les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['Stemming', 'is', 'an', 'essential', 'part', 'of', 'natural', 'language', 'processing', '.', 'It', 'involves', 'reducing', 'words', 'to', 'their', 'base', 'form', '.']\n",
      "\n",
      "\n",
      "Stems: ['stem', 'be', 'an', 'essential', 'part', 'of', 'natural', 'language', 'processing', '.', '-pron-', 'involve', 'reduce', 'word', 'to', '-pron-', 'base', 'form', '.']\n"
     ]
    }
   ],
   "source": [
    "# Fonction de stemming personnalisée avec SpaCy\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 1 \n",
    "\n",
    "Question : Créez une phrase complexe en anglais.\n",
    "\n",
    "Question : Utilisez SpaCy pour effectuer la lemmatisation sur les mots de la phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['Lemmatization', 'is', 'an', 'essential', 'part', 'of', 'natural', 'language', 'processing', '.', 'It', 'involves', 'reducing', 'words', 'to', 'their', 'base', 'form', '.']\n",
      "\n",
      "\n",
      "Lemmas: ['lemmatization', 'be', 'an', 'essential', 'part', 'of', 'natural', 'language', 'processing', '.', '-pron-', 'involve', 'reduce', 'word', 'to', '-pron-', 'base', 'form', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# # Téléchargement du modèle de langue anglaise\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Création d'une phrase complexe\n",
    "text = \"Lemmatization is an essential part of natural language processing. It involves reducing words to their base form.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 2\n",
    "\n",
    "Question : Créez une fonction custom_spacy_lemmatizer qui prend une phrase en entrée, utilise SpaCy pour effectuer la lemmatisation, et renvoie les lemmes en minuscules.\n",
    "\n",
    "Question : Appliquez votre fonction custom_spacy_lemmatizer à une phrase de votre choix et affichez les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['Lemmatization', 'is', 'an', 'essential', 'part', 'of', 'natural', 'language', 'processing', '.', 'It', 'involves', 'reducing', 'words', 'to', 'their', 'base', 'form', '.']\n",
      "\n",
      "\n",
      "Lemmas: ['lemmatization', 'be', 'an', 'essential', 'part', 'of', 'natural', 'language', 'processing', '.', '-pron-', 'involve', 'reduce', 'word', 'to', '-pron-', 'base', 'form', '.']\n"
     ]
    }
   ],
   "source": [
    "# Fonction de lemmatisation personnalisée avec SpaCy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 1\n",
    "\n",
    "Question : Créez une phrase complexe en anglais.\n",
    "\n",
    "Question : Utilisez SpaCy pour filtrer les stopwords de la phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['Stopwords', 'are', 'common', 'words', 'that', 'are', 'often', 'removed', 'during', 'text', 'preprocessing', '.']\n",
      "Filtered words (without stopwords): ['stopwords', 'common', 'words', 'removed', 'text', 'preprocessing', '.']\n",
      "SpaCy Stopwords: {'that', 'is', 'being', 'this', 'make', 'give', 'yet', 'besides', 'get', 'former', 'herein', 'might', 'alone', 'amount', 'third', 'anyone', 'after', 'seemed', 'so', 'there', 'together', 'me', 'our', 'serious', 're', 'can', 'whither', 'via', 'least', 'both', 'many', 'was', 'latterly', 'behind', 'mine', 'namely', 'each', 'i', 'through', 'any', 'put', 'along', 'either', 'himself', 'keep', 'it', 'does', 'on', 'all', 'therefore', 'themselves', 'full', 'seem', 'neither', 'towards', 'who', 'again', 'whereas', 'at', 'whose', 'seems', 'although', 'well', 'whom', 'almost', 'whence', 'below', 'name', 'they', 'up', 'one', 'moreover', 'nowhere', 'quite', 'several', 'afterwards', 'toward', 'are', 'been', 'none', 'indeed', 'however', 'nine', 'whatever', 'fifteen', 'had', 'eight', 'someone', 'already', 'fifty', 'last', 'while', 'four', 'anyhow', 'hereby', 'not', 'those', 'we', 'somewhere', 'since', 'mostly', 'beside', 'cannot', 'first', 'bottom', 'say', 'should', 'with', 'no', 'nor', 'ten', 'various', 'your', 'ours', 'used', 'whoever', 'forty', 'itself', 'much', 'take', 'twelve', 'became', 'another', 'between', 'top', 'to', 'very', 'beforehand', 'doing', 'will', 'of', 'whenever', 'made', 'move', 'within', 'two', 'how', 'becomes', 'or', 'yourselves', 'may', 'otherwise', 'here', 'once', 'during', 'have', 'yours', 'thereupon', 'an', 'next', 'out', 'must', 'myself', 'against', 'until', 'becoming', 'she', 'them', 'everywhere', 'whereby', 'what', 'by', 'less', 'always', 'same', 'their', 'he', 'ever', 'noone', 'something', 'why', 'could', 'some', 'than', 'anyway', 'everything', 'side', 'under', 'go', 'seeming', 'down', 'nothing', 'please', 'off', 'us', 'six', 'my', 'every', 'everyone', 'enough', 'without', 'onto', 'hers', 'for', 'his', 'over', 'as', 'done', 'formerly', 'into', 'thereafter', 'am', 'due', 'front', 'just', 'be', 'because', 'call', 'hereafter', 'somehow', 'him', 'thence', 'ca', 'throughout', 'three', 'unless', 'upon', 'has', 'whole', 'the', 'own', 'yourself', 'part', 'really', 'its', 'few', 'her', 'else', 'nobody', 'a', 'then', 'thereby', 'back', 'from', 'see', 'too', 'did', 'sometime', 'therein', 'above', 'regarding', 'often', 'across', 'become', 'such', 'herself', 'eleven', 'and', 'even', 'per', 'five', 'perhaps', 'rather', 'using', 'were', 'whether', 'most', 'except', 'anything', 'in', 'show', 'among', 'further', 'amongst', 'if', 'do', 'nevertheless', 'thus', 'but', 'where', 'around', 'meanwhile', 'more', 'other', 'still', 'whereupon', 'thru', 'sixty', 'hereupon', 'hence', 'never', 'before', 'though', 'twenty', 'beyond', 'elsewhere', 'latter', 'whereafter', 'these', 'wherever', 'now', 'wherein', 'empty', 'anywhere', 'which', 'also', 'about', 'others', 'ourselves', 'you', 'sometimes', 'only', 'would', 'hundred', 'when'}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Téléchargement du modèle de langue anglaise\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Création d'une phrase complexe\n",
    "text = \"Stopwords are common words that are often removed during text preprocessing.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 2\n",
    "\n",
    "Question : Créez une fonction remove_stopwords qui prend une phrase en entrée, utilise SpaCy pour filtrer les stopwords, et renvoie les mots restants en minuscules.\n",
    "\n",
    "Question : Appliquez votre fonction remove_stopwords à une phrase de votre choix et affichez les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['Stopwords', 'are', 'common', 'words', 'that', 'are', 'often', 'removed', 'during', 'text', 'preprocessing', '.']\n",
      "\n",
      "\n",
      "Filtered words (without stopwords): ['stopwords', 'common', 'words', 'removed', 'text', 'preprocessing', '.']\n"
     ]
    }
   ],
   "source": [
    "# Fonction de filtrage des stopwords avec SpaCy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codez une fonction 'preprocess_text_spacy' qui applique les méthodes de preprocessing vues en cours et permet d'obtenir les résultats prétraités suivants :\n",
    "\n",
    "NB : n'oublier pas de traiter les caractères spéciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_spacy(text):\n",
    "    pass\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte brut: Hello, I know that Natural Language Processing is a fascinating field!!!\n",
      "\n",
      "\n",
      "Texte prétraité avec SpaCy: hello know natural language processing fascinating field\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation avec SpaCy\n",
    "raw_text = \"Hello, I know that Natural Language Processing is a fascinating field!!!\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
